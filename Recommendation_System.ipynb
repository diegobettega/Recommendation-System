{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S37hdGAtxNL3"
   },
   "source": [
    "Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363,
     "status": "ok",
     "timestamp": 1587396716756,
     "user": {
      "displayName": "Diego Bettega",
      "photoUrl": "",
      "userId": "18155426968625496378"
     },
     "user_tz": -60
    },
    "id": "Sn5ePUQ1wcGJ",
    "outputId": "655d1f0f-ccb3-4170-9750-4058b6358c71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader  \n",
    "from surprise import SVD\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.accuracy import rmse\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from IPython.display import display, Image\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # change the cell width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgK4kRYSxkzA"
   },
   "source": [
    "Read and explore the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9830,
     "status": "ok",
     "timestamp": 1587396756001,
     "user": {
      "displayName": "Diego Bettega",
      "photoUrl": "",
      "userId": "18155426968625496378"
     },
     "user_tz": -60
    },
    "id": "8rLndA1EwcXw",
    "outputId": "81d07b99-ee18-4df9-d825-6c7193687b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 7824482 rows, and 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AKM1MP6P0OYPR</td>\n",
       "      <td>0132793040</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId   productId  Rating\n",
       "0   AKM1MP6P0OYPR  0132793040     5.0\n",
       "1  A2CX7LUOHB2NDG  0321732944     5.0\n",
       "2  A2NWSAGRHCP8N5  0439886341     1.0\n",
       "3  A2WNBOD3WNDNKT  0439886341     3.0\n",
       "4  A1GI0U4ZRJA8WN  0439886341     1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ratings_Electronics.csv', header=None)\n",
    "df.columns = ['userId', 'productId', 'Rating', 'timestamp']\n",
    "df.drop(['timestamp'], axis=1, inplace=True)\n",
    "print('This dataset has ' + str(df.shape[0]) + ' rows, and ' + str(df.shape[1]) + ' columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNzcGJ7V1MJu"
   },
   "source": [
    "Checking for data types and NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13098,
     "status": "ok",
     "timestamp": 1587396772501,
     "user": {
      "displayName": "Diego Bettega",
      "photoUrl": "",
      "userId": "18155426968625496378"
     },
     "user_tz": -60
    },
    "id": "hyO61wmowccc",
    "outputId": "d5589e00-2174-47ca-f379-dd4a57a63012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7824482 entries, 0 to 7824481\n",
      "Data columns (total 3 columns):\n",
      "userId       object\n",
      "productId    object\n",
      "Rating       float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 179.1+ MB\n",
      "\n",
      "\n",
      "\n",
      "Total NaN values =  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.info()\n",
    "msno.matrix(df)\n",
    "print('\\n\\n\\nTotal NaN values = ', df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2nfmH0MK1yo1"
   },
   "source": [
    "Check the distribution of the ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10898,
     "status": "ok",
     "timestamp": 1587396772781,
     "user": {
      "displayName": "Diego Bettega",
      "photoUrl": "",
      "userId": "18155426968625496378"
     },
     "user_tz": -60
    },
    "id": "mVXrF2REwcVH",
    "outputId": "8bf6485e-e52d-4eb7-c869-7c61f63d33ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution = sns.countplot(df['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12860,
     "status": "ok",
     "timestamp": 1587396776723,
     "user": {
      "displayName": "Diego Bettega",
      "photoUrl": "",
      "userId": "18155426968625496378"
     },
     "user_tz": -60
    },
    "id": "SNHbJxQzwcQz",
    "outputId": "573f8ae9-fdf9-4e4c-da7d-909498921ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4201696 unique users in the dataset\n",
      "There are 476002 unique products in the dataset\n"
     ]
    }
   ],
   "source": [
    "print('There are {} unique users in the dataset'.format(df.userId.nunique()))\n",
    "print('There are {} unique products in the dataset'.format(df.productId.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9S7u79Y7VqC"
   },
   "source": [
    "Take a subset of the dataset (users with at least 50 ratings) to make it denser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31763,
     "status": "ok",
     "timestamp": 1587396796578,
     "user": {
      "displayName": "Diego Bettega",
      "photoUrl": "",
      "userId": "18155426968625496378"
     },
     "user_tz": -60
    },
    "id": "RnLkwECywcPZ",
    "outputId": "4088f66a-bb15-4fec-8de9-6c9b3ac6d7ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now there are 1540 unique users in the dataset\n",
      "Now there are 48190 unique products in the dataset\n"
     ]
    }
   ],
   "source": [
    "df_userId = df.groupby(['userId']).agg('count')\n",
    "selected_users = list(df_userId[df_userId['Rating']>=50].index)\n",
    "df = df[df['userId'].isin(selected_users)]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('Now there are {} unique users in the dataset'.format(df.userId.nunique()))\n",
    "print('Now there are {} unique products in the dataset'.format(df.productId.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yxNP1om71bO"
   },
   "source": [
    "Shuffle the dataset because some learning algorithms are sensitive to the order of the training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbmyG4vVwcMi"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SlJnAvt8Nmx"
   },
   "source": [
    "Spliting the data in train and test set\n",
    "\n",
    "I am going to use 70% of data for building the algorithm and 30% for the final test to have a realistic evaluation of the model in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1587396797578,
     "user": {
      "displayName": "Diego Bettega",
      "photoUrl": "",
      "userId": "18155426968625496378"
     },
     "user_tz": -60
    },
    "id": "yubfEJmiwcLF",
    "outputId": "2c522bb9-9671-4ae7-c811-e8381fc0af6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88109 records (70%) are used for traning \n",
      "37762 records (30%) are used for testing\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=1)\n",
    "for train_index, test_index in split.split(df, df['Rating']):\n",
    "    train = df.loc[train_index]\n",
    "    train.reset_index(inplace=True,drop=True)\n",
    "    test = df.loc[test_index]\n",
    "    test.reset_index(inplace=True,drop=True)\n",
    "\n",
    "print('%.0f records (%.0f%%) are used for traning \\n%.0f records (%.0f%%) are used for testing' % (len(train), (100*len(train)/(len(df))), len(test), (100*len(test)/(len(df)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8O5IOPDCBGFp"
   },
   "source": [
    "Build Popularity Recommender model (Non-personalised) to consider both the mean and the number of ratings in equal measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1706,
     "status": "ok",
     "timestamp": 1587396798315,
     "user": {
      "displayName": "Diego Bettega",
      "photoUrl": "",
      "userId": "18155426968625496378"
     },
     "user_tz": -60
    },
    "id": "coupDpx966SS",
    "outputId": "78857a9c-9814-461c-8d17-23c4219cd08e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_ratings</th>\n",
       "      <th>count_ratings</th>\n",
       "      <th>score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>4.876923</td>\n",
       "      <td>130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>4.222973</td>\n",
       "      <td>148</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>4.780702</td>\n",
       "      <td>114</td>\n",
       "      <td>0.928038</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>4.775701</td>\n",
       "      <td>107</td>\n",
       "      <td>0.901576</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B00829TIEK</td>\n",
       "      <td>4.476190</td>\n",
       "      <td>105</td>\n",
       "      <td>0.853664</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean_ratings  count_ratings     score  Rank\n",
       "productId                                              \n",
       "B003ES5ZUU      4.876923            130  1.000000   1.0\n",
       "B0088CJT4U      4.222973            148  0.977778   2.0\n",
       "B007WTAJTO      4.780702            114  0.928038   3.0\n",
       "B000N99BBC      4.775701            107  0.901576   4.0\n",
       "B00829TIEK      4.476190            105  0.853664   5.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ratings = train.groupby('productId')['Rating'].mean()\n",
    "count_ratings = train.groupby('productId')['Rating'].count()\n",
    "popular_rec_system = pd.concat([pd.DataFrame(mean_ratings), pd.DataFrame(count_ratings)], axis=1)\n",
    "popular_rec_system.columns = ['mean_ratings', 'count_ratings']\n",
    "popular_rec_system['score'] = (popular_rec_system['mean_ratings']-1)/4 + (popular_rec_system['count_ratings']-popular_rec_system['count_ratings'].min()) / (popular_rec_system['count_ratings'].max()-popular_rec_system['count_ratings'].min())\n",
    "popular_rec_system['score'] = (popular_rec_system['score']-popular_rec_system['score'].min()) / (popular_rec_system['score'].max()-popular_rec_system['score'].min())\n",
    "popular_rec_system = popular_rec_system.sort_values('score', ascending=False)\n",
    "popular_rec_system['Rank'] = popular_rec_system['score'].rank(ascending=0, method='first') \n",
    "popular_rec_system = popular_rec_system.head(5)\n",
    "popular_rec_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the Popularity Recommender model on the test set only for the top 5 products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score: 0.83\n"
     ]
    }
   ],
   "source": [
    "df_popular_rec_system = pd.merge(test[test['productId'].isin(list(popular_rec_system.index))], popular_rec_system, left_on='productId', right_on='productId', how='left', suffixes=('', 'predicted')).drop(['count_ratings','score','Rank'], axis=1)\n",
    "print('RMSE score:', round(mean_squared_error(df_popular_rec_system['Rating'].values, df_popular_rec_system['mean_ratings'].values, squared=False),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ajk7fDmaGcnD"
   },
   "source": [
    "Build Collaborative Filtering model. I will start using KNNWithMeans with a grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best Parameters: {'name': 'msd', 'min_support': 3, 'user_based': False}\n",
      "RMSE score: 1.07\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df.copy()[['userId', 'productId', 'Rating']], reader=reader)\n",
    "\n",
    "param_grid = {'name': ['msd', 'cosine'],\n",
    "               'min_support': [3, 4, 5],\n",
    "               'user_based': [False, True]}\n",
    "\n",
    "gs_knn = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=3)\n",
    "gs_knn.fit(data)\n",
    "\n",
    "print('Best Parameters:', gs_knn.best_params['rmse'])\n",
    "print('RMSE score:', round(gs_knn.best_score['rmse'],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also try SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_epochs': 2, 'n_factors': 100, 'lr_all': 0.005, 'reg_all': 0.4}\n",
      "RMSE score: 1.02\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [1, 2],\n",
    "              'n_factors': [100, 200],\n",
    "              'lr_all': [0.004, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "\n",
    "gs_svd = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs_svd.fit(data)\n",
    "\n",
    "print('Best Parameters:', gs_svd.best_params['rmse'])\n",
    "print('RMSE score:', round(gs_svd.best_score['rmse'],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the best algo from the 2 grid searches and I train on the treaining set and validate on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score: 1.01\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = surprise_train_test_split(data, test_size=.3)\n",
    "\n",
    "algo = gs_svd.best_estimator['rmse']\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "print('RMSE score:', round(accuracy.rmse(predictions, verbose=False),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top 5 recommendations for each user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec 2</th>\n",
       "      <th>Rec 3</th>\n",
       "      <th>Rec 4</th>\n",
       "      <th>Rec 5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>A1901NTE8LFJF6</td>\n",
       "      <td>B001769K3O</td>\n",
       "      <td>B003GALRIA</td>\n",
       "      <td>B008AT6BMY</td>\n",
       "      <td>B003B4AVRE</td>\n",
       "      <td>B001VEIYAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AT53ZTTO707MB</td>\n",
       "      <td>B00DTZYHX4</td>\n",
       "      <td>B00ENZRS76</td>\n",
       "      <td>B006OM75I8</td>\n",
       "      <td>B009A68TMQ</td>\n",
       "      <td>B00IMZKDOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ABIVKBMSIPEDY</td>\n",
       "      <td>B00GV4UHDO</td>\n",
       "      <td>B00HVT27B8</td>\n",
       "      <td>B004SKBIH2</td>\n",
       "      <td>B004C13VWC</td>\n",
       "      <td>B00FR6VL50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A3QMJMTLJC34QC</td>\n",
       "      <td>B004YKXGIK</td>\n",
       "      <td>B003HFCDLY</td>\n",
       "      <td>B001HTX1XQ</td>\n",
       "      <td>B000ADKTRG</td>\n",
       "      <td>B002TMRZOQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A2J96FILPQA01</td>\n",
       "      <td>B000VX6XL6</td>\n",
       "      <td>B0019EHU8G</td>\n",
       "      <td>B008EQZ25K</td>\n",
       "      <td>B0052L77QW</td>\n",
       "      <td>B0041OSQB6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Rec 1       Rec 2       Rec 3       Rec 4       Rec 5\n",
       "userId                                                                    \n",
       "A1901NTE8LFJF6  B001769K3O  B003GALRIA  B008AT6BMY  B003B4AVRE  B001VEIYAC\n",
       "AT53ZTTO707MB   B00DTZYHX4  B00ENZRS76  B006OM75I8  B009A68TMQ  B00IMZKDOS\n",
       "ABIVKBMSIPEDY   B00GV4UHDO  B00HVT27B8  B004SKBIH2  B004C13VWC  B00FR6VL50\n",
       "A3QMJMTLJC34QC  B004YKXGIK  B003HFCDLY  B001HTX1XQ  B000ADKTRG  B002TMRZOQ\n",
       "A2J96FILPQA01   B000VX6XL6  B0019EHU8G  B008EQZ25K  B0052L77QW  B0041OSQB6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_n(predictions, n=5):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "top_n = get_top_n(predictions)\n",
    "\n",
    "users = []\n",
    "recommendations = []\n",
    "for uid, user_ratings in top_n.items():\n",
    "    users.append(uid)\n",
    "    recommendations.append([iid for (iid, _) in user_ratings])\n",
    "\n",
    "recommendations = pd.concat([pd.DataFrame(users), pd.DataFrame(recommendations)], axis=1)\n",
    "recommendations.columns = ['userId', 'Rec 1', 'Rec 2', 'Rec 3', 'Rec 4', 'Rec 5']\n",
    "recommendations.set_index('userId', drop=True, inplace=True)\n",
    "recommendations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also use Autoencoders with PyTorch to create a recommendations system. First I will create a match table to convert the User ID: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>new_userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A2CIQEY05SPHTZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A370XYLIZCSK1Y</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ANTN61S4L7WG9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A2HPJKM7L4EOQB</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A1MRPX3RM48T2I</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1535</td>\n",
       "      <td>A1WUQF5HWBAQJU</td>\n",
       "      <td>1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1536</td>\n",
       "      <td>A30ADSBTWCORYC</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1537</td>\n",
       "      <td>A17NVM7IAPF2NS</td>\n",
       "      <td>1538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1538</td>\n",
       "      <td>A2HBOG4LVIY15L</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1539</td>\n",
       "      <td>A3KTWUXXB8KKC7</td>\n",
       "      <td>1540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1540 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId  new_userId\n",
       "0     A2CIQEY05SPHTZ           1\n",
       "1     A370XYLIZCSK1Y           2\n",
       "2      ANTN61S4L7WG9           3\n",
       "3     A2HPJKM7L4EOQB           4\n",
       "4     A1MRPX3RM48T2I           5\n",
       "...              ...         ...\n",
       "1535  A1WUQF5HWBAQJU        1536\n",
       "1536  A30ADSBTWCORYC        1537\n",
       "1537  A17NVM7IAPF2NS        1538\n",
       "1538  A2HBOG4LVIY15L        1539\n",
       "1539  A3KTWUXXB8KKC7        1540\n",
       "\n",
       "[1540 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userId_match_table = pd.concat([pd.DataFrame(df['userId'].unique()), pd.DataFrame(np.arange(0,df['userId'].nunique())+1)],axis=1)\n",
    "userId_match_table.columns = ['userId', 'new_userId']\n",
    "userId_match_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I create a table to convert the Product ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>new_productId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B000W9UYL4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B00347L6I6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B003FMVPFY</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B002DW97WK</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B0015HYPOO</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48185</td>\n",
       "      <td>B002Q5KOCQ</td>\n",
       "      <td>48186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48186</td>\n",
       "      <td>B000M4F9GO</td>\n",
       "      <td>48187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48187</td>\n",
       "      <td>B004RCNRL6</td>\n",
       "      <td>48188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48188</td>\n",
       "      <td>B00008ELLG</td>\n",
       "      <td>48189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48189</td>\n",
       "      <td>B0055E8B0M</td>\n",
       "      <td>48190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48190 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        productId  new_productId\n",
       "0      B000W9UYL4              1\n",
       "1      B00347L6I6              2\n",
       "2      B003FMVPFY              3\n",
       "3      B002DW97WK              4\n",
       "4      B0015HYPOO              5\n",
       "...           ...            ...\n",
       "48185  B002Q5KOCQ          48186\n",
       "48186  B000M4F9GO          48187\n",
       "48187  B004RCNRL6          48188\n",
       "48188  B00008ELLG          48189\n",
       "48189  B0055E8B0M          48190\n",
       "\n",
       "[48190 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productId_match_table = pd.concat([pd.DataFrame(df['productId'].unique()), pd.DataFrame(np.arange(0,df['productId'].nunique())+1)],axis=1)\n",
    "productId_match_table.columns = ['productId', 'new_productId']\n",
    "productId_match_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I apply these changes mapping the new IDs to the original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_userId</th>\n",
       "      <th>new_productId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125866</td>\n",
       "      <td>324</td>\n",
       "      <td>1070</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125867</td>\n",
       "      <td>1445</td>\n",
       "      <td>486</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125868</td>\n",
       "      <td>439</td>\n",
       "      <td>48189</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125869</td>\n",
       "      <td>668</td>\n",
       "      <td>48190</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125870</td>\n",
       "      <td>1151</td>\n",
       "      <td>33649</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125871 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        new_userId  new_productId  Rating\n",
       "0                1              1       2\n",
       "1                2              2       5\n",
       "2                3              3       5\n",
       "3                4              4       4\n",
       "4                5              5       4\n",
       "...            ...            ...     ...\n",
       "125866         324           1070       5\n",
       "125867        1445            486       4\n",
       "125868         439          48189       4\n",
       "125869         668          48190       2\n",
       "125870        1151          33649       5\n",
       "\n",
       "[125871 rows x 3 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_autoencoders = pd.merge(df.copy(), userId_match_table, left_on='userId', right_on='userId', how='left').drop('userId', axis=1)\n",
    "df_autoencoders = pd.merge(df_autoencoders, productId_match_table, left_on='productId', right_on='productId', how='left').drop('productId', axis=1)\n",
    "df_autoencoders = df_autoencoders[['new_userId', 'new_productId', 'Rating']]\n",
    "df_autoencoders = df_autoencoders.astype(int)\n",
    "df_autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the training and test set into arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(train, dtype = 'int')\n",
    "test_set = np.array(test, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the number of users and products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_products = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the data into an array with users in lines and products in columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_products = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_products)\n",
    "        ratings[id_products - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the data into Torch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the architecture of the Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_products, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_products)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the SAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(4.3693)\n",
      "epoch: 2 loss: tensor(4.3607)\n",
      "epoch: 3 loss: tensor(4.3410)\n",
      "epoch: 4 loss: tensor(4.3192)\n",
      "epoch: 5 loss: tensor(4.2944)\n",
      "epoch: 6 loss: tensor(4.2654)\n",
      "epoch: 7 loss: tensor(4.2309)\n",
      "epoch: 8 loss: tensor(4.1906)\n",
      "epoch: 9 loss: tensor(4.1464)\n",
      "epoch: 10 loss: tensor(4.1014)\n",
      "epoch: 11 loss: tensor(4.0580)\n",
      "epoch: 12 loss: tensor(4.0170)\n",
      "epoch: 13 loss: tensor(3.9783)\n",
      "epoch: 14 loss: tensor(3.9417)\n",
      "epoch: 15 loss: tensor(3.9069)\n",
      "epoch: 16 loss: tensor(3.8735)\n",
      "epoch: 17 loss: tensor(3.8415)\n",
      "epoch: 18 loss: tensor(3.8108)\n",
      "epoch: 19 loss: tensor(3.7811)\n",
      "epoch: 20 loss: tensor(3.7524)\n",
      "epoch: 21 loss: tensor(3.7247)\n",
      "epoch: 22 loss: tensor(3.6978)\n",
      "epoch: 23 loss: tensor(3.6717)\n",
      "epoch: 24 loss: tensor(3.6464)\n",
      "epoch: 25 loss: tensor(3.6217)\n",
      "epoch: 26 loss: tensor(3.5977)\n",
      "epoch: 27 loss: tensor(3.5744)\n",
      "epoch: 28 loss: tensor(3.5516)\n",
      "epoch: 29 loss: tensor(3.5294)\n",
      "epoch: 30 loss: tensor(3.5077)\n",
      "epoch: 31 loss: tensor(3.4865)\n",
      "epoch: 32 loss: tensor(3.4658)\n",
      "epoch: 33 loss: tensor(3.4455)\n",
      "epoch: 34 loss: tensor(3.4257)\n",
      "epoch: 35 loss: tensor(3.4063)\n",
      "epoch: 36 loss: tensor(3.3873)\n",
      "epoch: 37 loss: tensor(3.3687)\n",
      "epoch: 38 loss: tensor(3.3504)\n",
      "epoch: 39 loss: tensor(3.3325)\n",
      "epoch: 40 loss: tensor(3.3149)\n",
      "epoch: 41 loss: tensor(3.2977)\n",
      "epoch: 42 loss: tensor(3.2808)\n",
      "epoch: 43 loss: tensor(3.2642)\n",
      "epoch: 44 loss: tensor(3.2478)\n",
      "epoch: 45 loss: tensor(3.2318)\n",
      "epoch: 46 loss: tensor(3.2160)\n",
      "epoch: 47 loss: tensor(3.2005)\n",
      "epoch: 48 loss: tensor(3.1852)\n",
      "epoch: 49 loss: tensor(3.1702)\n",
      "epoch: 50 loss: tensor(3.1555)\n",
      "epoch: 51 loss: tensor(3.1409)\n",
      "epoch: 52 loss: tensor(3.1266)\n",
      "epoch: 53 loss: tensor(3.1125)\n",
      "epoch: 54 loss: tensor(3.0986)\n",
      "epoch: 55 loss: tensor(3.0849)\n",
      "epoch: 56 loss: tensor(3.0714)\n",
      "epoch: 57 loss: tensor(3.0581)\n",
      "epoch: 58 loss: tensor(3.0450)\n",
      "epoch: 59 loss: tensor(3.0321)\n",
      "epoch: 60 loss: tensor(3.0193)\n",
      "epoch: 61 loss: tensor(3.0067)\n",
      "epoch: 62 loss: tensor(2.9943)\n",
      "epoch: 63 loss: tensor(2.9821)\n",
      "epoch: 64 loss: tensor(2.9700)\n",
      "epoch: 65 loss: tensor(2.9581)\n",
      "epoch: 66 loss: tensor(2.9463)\n",
      "epoch: 67 loss: tensor(2.9346)\n",
      "epoch: 68 loss: tensor(2.9231)\n",
      "epoch: 69 loss: tensor(2.9118)\n",
      "epoch: 70 loss: tensor(2.9006)\n",
      "epoch: 71 loss: tensor(2.8895)\n",
      "epoch: 72 loss: tensor(2.8785)\n",
      "epoch: 73 loss: tensor(2.8677)\n",
      "epoch: 74 loss: tensor(2.8570)\n",
      "epoch: 75 loss: tensor(2.8464)\n",
      "epoch: 76 loss: tensor(2.8359)\n",
      "epoch: 77 loss: tensor(2.8256)\n",
      "epoch: 78 loss: tensor(2.8154)\n",
      "epoch: 79 loss: tensor(2.8052)\n",
      "epoch: 80 loss: tensor(2.7952)\n",
      "epoch: 81 loss: tensor(2.7853)\n",
      "epoch: 82 loss: tensor(2.7755)\n",
      "epoch: 83 loss: tensor(2.7658)\n",
      "epoch: 84 loss: tensor(2.7562)\n",
      "epoch: 85 loss: tensor(2.7467)\n",
      "epoch: 86 loss: tensor(2.7373)\n",
      "epoch: 87 loss: tensor(2.7280)\n",
      "epoch: 88 loss: tensor(2.7187)\n",
      "epoch: 89 loss: tensor(2.7096)\n",
      "epoch: 90 loss: tensor(2.7005)\n",
      "epoch: 91 loss: tensor(2.6916)\n",
      "epoch: 92 loss: tensor(2.6827)\n",
      "epoch: 93 loss: tensor(2.6739)\n",
      "epoch: 94 loss: tensor(2.6652)\n",
      "epoch: 95 loss: tensor(2.6566)\n",
      "epoch: 96 loss: tensor(2.6480)\n",
      "epoch: 97 loss: tensor(2.6396)\n",
      "epoch: 98 loss: tensor(2.6312)\n",
      "epoch: 99 loss: tensor(2.6228)\n",
      "epoch: 100 loss: tensor(2.6146)\n",
      "epoch: 101 loss: tensor(2.6064)\n",
      "epoch: 102 loss: tensor(2.5983)\n",
      "epoch: 103 loss: tensor(2.5903)\n",
      "epoch: 104 loss: tensor(2.5823)\n",
      "epoch: 105 loss: tensor(2.5744)\n",
      "epoch: 106 loss: tensor(2.5666)\n",
      "epoch: 107 loss: tensor(2.5588)\n",
      "epoch: 108 loss: tensor(2.5511)\n",
      "epoch: 109 loss: tensor(2.5435)\n",
      "epoch: 110 loss: tensor(2.5359)\n",
      "epoch: 111 loss: tensor(2.5284)\n",
      "epoch: 112 loss: tensor(2.5209)\n",
      "epoch: 113 loss: tensor(2.5135)\n",
      "epoch: 114 loss: tensor(2.5062)\n",
      "epoch: 115 loss: tensor(2.4989)\n",
      "epoch: 116 loss: tensor(2.4916)\n",
      "epoch: 117 loss: tensor(2.4845)\n",
      "epoch: 118 loss: tensor(2.4773)\n",
      "epoch: 119 loss: tensor(2.4703)\n",
      "epoch: 120 loss: tensor(2.4633)\n",
      "epoch: 121 loss: tensor(2.4563)\n",
      "epoch: 122 loss: tensor(2.4494)\n",
      "epoch: 123 loss: tensor(2.4425)\n",
      "epoch: 124 loss: tensor(2.4357)\n",
      "epoch: 125 loss: tensor(2.4290)\n",
      "epoch: 126 loss: tensor(2.4223)\n",
      "epoch: 127 loss: tensor(2.4156)\n",
      "epoch: 128 loss: tensor(2.4090)\n",
      "epoch: 129 loss: tensor(2.4024)\n",
      "epoch: 130 loss: tensor(2.3959)\n",
      "epoch: 131 loss: tensor(2.3894)\n",
      "epoch: 132 loss: tensor(2.3830)\n",
      "epoch: 133 loss: tensor(2.3766)\n",
      "epoch: 134 loss: tensor(2.3702)\n",
      "epoch: 135 loss: tensor(2.3639)\n",
      "epoch: 136 loss: tensor(2.3577)\n",
      "epoch: 137 loss: tensor(2.3515)\n",
      "epoch: 138 loss: tensor(2.3453)\n",
      "epoch: 139 loss: tensor(2.3391)\n",
      "epoch: 140 loss: tensor(2.3330)\n",
      "epoch: 141 loss: tensor(2.3270)\n",
      "epoch: 142 loss: tensor(2.3210)\n",
      "epoch: 143 loss: tensor(2.3150)\n",
      "epoch: 144 loss: tensor(2.3090)\n",
      "epoch: 145 loss: tensor(2.3031)\n",
      "epoch: 146 loss: tensor(2.2973)\n",
      "epoch: 147 loss: tensor(2.2914)\n",
      "epoch: 148 loss: tensor(2.2856)\n",
      "epoch: 149 loss: tensor(2.2799)\n",
      "epoch: 150 loss: tensor(2.2742)\n",
      "epoch: 151 loss: tensor(2.2685)\n",
      "epoch: 152 loss: tensor(2.2628)\n",
      "epoch: 153 loss: tensor(2.2572)\n",
      "epoch: 154 loss: tensor(2.2516)\n",
      "epoch: 155 loss: tensor(2.2460)\n",
      "epoch: 156 loss: tensor(2.2405)\n",
      "epoch: 157 loss: tensor(2.2350)\n",
      "epoch: 158 loss: tensor(2.2296)\n",
      "epoch: 159 loss: tensor(2.2241)\n",
      "epoch: 160 loss: tensor(2.2188)\n",
      "epoch: 161 loss: tensor(2.2134)\n",
      "epoch: 162 loss: tensor(2.2081)\n",
      "epoch: 163 loss: tensor(2.2028)\n",
      "epoch: 164 loss: tensor(2.1975)\n",
      "epoch: 165 loss: tensor(2.1923)\n",
      "epoch: 166 loss: tensor(2.1870)\n",
      "epoch: 167 loss: tensor(2.1819)\n",
      "epoch: 168 loss: tensor(2.1767)\n",
      "epoch: 169 loss: tensor(2.1716)\n",
      "epoch: 170 loss: tensor(2.1665)\n",
      "epoch: 171 loss: tensor(2.1614)\n",
      "epoch: 172 loss: tensor(2.1564)\n",
      "epoch: 173 loss: tensor(2.1513)\n",
      "epoch: 174 loss: tensor(2.1464)\n",
      "epoch: 175 loss: tensor(2.1414)\n",
      "epoch: 176 loss: tensor(2.1365)\n",
      "epoch: 177 loss: tensor(2.1316)\n",
      "epoch: 178 loss: tensor(2.1267)\n",
      "epoch: 179 loss: tensor(2.1218)\n",
      "epoch: 180 loss: tensor(2.1170)\n",
      "epoch: 181 loss: tensor(2.1122)\n",
      "epoch: 182 loss: tensor(2.1074)\n",
      "epoch: 183 loss: tensor(2.1026)\n",
      "epoch: 184 loss: tensor(2.0979)\n",
      "epoch: 185 loss: tensor(2.0932)\n",
      "epoch: 186 loss: tensor(2.0885)\n",
      "epoch: 187 loss: tensor(2.0838)\n",
      "epoch: 188 loss: tensor(2.0792)\n",
      "epoch: 189 loss: tensor(2.0746)\n",
      "epoch: 190 loss: tensor(2.0700)\n",
      "epoch: 191 loss: tensor(2.0654)\n",
      "epoch: 192 loss: tensor(2.0609)\n",
      "epoch: 193 loss: tensor(2.0564)\n",
      "epoch: 194 loss: tensor(2.0519)\n",
      "epoch: 195 loss: tensor(2.0474)\n",
      "epoch: 196 loss: tensor(2.0429)\n",
      "epoch: 197 loss: tensor(2.0385)\n",
      "epoch: 198 loss: tensor(2.0341)\n",
      "epoch: 199 loss: tensor(2.0297)\n",
      "epoch: 200 loss: tensor(2.0253)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_products/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3pL56bTRPoj"
   },
   "source": [
    "Popularity Recommender model had a RMSE of 0.83, however it has been calculated only considering the top 5 products. This model doesn't make any personalisation. I'd implement instead the Collaborative Filtering model, which had a RMSE slightly higer on the test set, but it has been calculated on the entire set (not only on the top 5 products) and it returns personalised recommendations."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Recommendation_System.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
